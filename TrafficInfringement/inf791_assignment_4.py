# -*- coding: utf-8 -*-
"""INF791 Assignment 4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TIxYQ4nmzswGkwRH3SDUXQ6-oqmTeQWm
"""

import pandas as pd
import numpy as np

# Load the dataset
#file_path = '/content/Accident _Dataset.xlsx' #Nothando
file_path = '/Accident _Dataset.xlsx'
dataset = pd.read_excel(file_path)

# Display the first few rows and some basic information to understand its structure
dataset.head(), dataset.info(), dataset.describe()



import pandas as pd
import matplotlib.pyplot as plt

# Count rows with any null values
null_rows = dataset.isnull().any(axis=1).sum()

# Count rows with no null values
filled_rows = len(dataset) - null_rows


# Data preparation
labels = ['Rows with Nulls', 'Fully Filled Rows']
sizes = [null_rows, filled_rows]
colors = ['#ff9999','#66b3ff']  # Custom colors for the segments
explode = (0.1, 0)  # "Explode" the 'Rows with Nulls' segment

# Plotting a donut-style pie chart
plt.figure(figsize=(8, 8))
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140,
        colors=colors, explode=explode, pctdistance=0.85, shadow=True)

# Draw a white circle at the center to create a donut shape
centre_circle = plt.Circle((0,0),0.70,fc='white')
plt.gca().add_artist(centre_circle)

# Customizing title with font size and color
plt.title('Proportion of Null Rows vs Filled Rows', fontsize=16, color='#333333')
plt.show()

import matplotlib.pyplot as plt

# Count null values for each column
null_counts = dataset.isnull().sum()

# Filter for columns with null values and sort in descending order
null_counts = null_counts[null_counts > 0].sort_values(ascending=False)

# Display the null counts
print(null_counts)

# Plot the null counts as a bar chart
plt.figure(figsize=(10, 6))
null_counts.plot(kind='bar', color='salmon')
plt.title('Columns with Null Values')
plt.xlabel('Columns')
plt.ylabel('Number of Null Values')
plt.xticks(rotation=45, ha='right')
plt.show()

# Calculate the percentage of missing values in each column
missing_values = dataset.isnull().mean() * 100
missing_values = missing_values[missing_values > 0].sort_values(ascending=False)

# Imputation for all categorical variables with 'Unknown'
categorical_columns = dataset.select_dtypes(include='object').columns
for column in categorical_columns:
    dataset[column].fillna("Unknown", inplace=True)

# Imputation for numerical columns - replacing missing values with mean
numerical_columns = dataset.select_dtypes(include=['float64', 'int64']).columns
for column in numerical_columns:
    dataset[column].fillna(dataset[column].mean(), inplace=True)

# Feature scaling for numerical columns - mean normalization
for column in numerical_columns:
    dataset[column] = (dataset[column] - dataset[column].mean()) / dataset[column].std()

# Removing outliers: Removing values outside of 3 standard deviations from the mean
for column in numerical_columns:
    mean = dataset[column].mean()
    std_dev = dataset[column].std()
    upper_limit = mean + 3 * std_dev
    lower_limit = mean - 3 * std_dev
    dataset = dataset[(dataset[column] >= lower_limit) & (dataset[column] <= upper_limit)]

# Confirm that no missing values remain
missing_values_after_final = dataset.isnull().sum().sum()
missing_values_after_final, dataset.shape

import seaborn as sns
import matplotlib.pyplot as plt

# Calculate the correlation matrix
correlation_matrix = dataset.corr()

# Display the correlation matrix
print(correlation_matrix)

# Optionally, plot a heatmap for better visualization
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", vmin=-1, vmax=1)
plt.title("Correlation Coefficient Matrix")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Calculate the correlation matrix
correlation_matrix = dataset.corr()

# Plot the heatmap with a larger figure size and increased font size
plt.figure(figsize=(17, 15))  # Increase figsize for better readability
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", vmin=-1, vmax=1, fmt=".2f",
            annot_kws={"size": 10})  # Increase font size in annot_kws
plt.title("Correlation Coefficient Matrix", fontsize=16)  # Increase title font size
plt.show()

import matplotlib.pyplot as plt

# Assuming 'traffic' is your DataFrame and 'Accident_severity' is the column name for severity
# Count the occurrences of each severity level
severity_counts = dataset['Accident_severity'].value_counts()

# Plotting the bar graph
plt.figure(figsize=(8, 6))
severity_counts.plot(kind='bar', color='skyblue')
plt.title('Accident Severity Distribution')
plt.xlabel('Severity Level')
plt.ylabel('Number of Accidents')
plt.xticks(rotation=45)
plt.show()

import matplotlib.pyplot as plt

# Assuming 'dataset' is your DataFrame and 'Cause_of_accident' is the column name for accident causes
# Count the occurrences of each cause of accident
severity_counts = dataset['Cause_of_accident'].value_counts()

# Plotting the bar graph with adjustments to prevent label overlap
plt.figure(figsize=(12, 6))  # Increase width for better spacing
severity_counts.plot(kind='bar', color='skyblue')
plt.title('Cause of Accident Distribution')
plt.xlabel('Cause of Accident')
plt.ylabel('Frequency')
plt.xticks(rotation=30, ha='right', fontsize=8)  # Adjust rotation, alignment, and font size
plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Replace non-standard time values with NaT, then convert to datetime
dataset['Time'] = pd.to_datetime(dataset['Time'], format='%H:%M:%S', errors='coerce').dt.hour

# Set the day of week as a categorical variable in the desired order
dataset['Day_of_week'] = pd.Categorical(dataset['Day_of_week'], categories=[
    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], ordered=True)

# Create a pivot table to count accidents by day of the week and hour, ignoring NaT values
accidents_pivot = dataset.pivot_table(index='Time', columns='Day_of_week', aggfunc='size', fill_value=0)

# Plot the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(accidents_pivot, cmap="YlOrRd", annot=True, fmt="d", cbar_kws={'label': 'Accident Frequency'})
plt.title('Accident Frequency by Day of the Week and Time of Day')
plt.xlabel('Day of the Week')
plt.ylabel('Hour of the Day')
plt.show()

"""# New Section"""

#encoding categorical variables
# Quick inspection of unique values in categorical columns to determine nominal vs. ordinal categories
categorical_overview = {col: dataset[col].unique() for col in categorical_columns}
categorical_overview
from sklearn.preprocessing import LabelEncoder

# Define label encoding for ordinal categories with specified order
ordinal_columns = {
    'Age_band_of_driver': ['Under 18', '18-30', '31-50', 'Over 51', 'Unknown'],
    'Educational_level': ['Illiterate', 'Elementary school', 'Writing & reading', 'Junior high school', 'High school', 'Above high school', 'Unknown'],
    'Driving_experience': ['No Licence', 'Below 1yr', '1-2yr', '2-5yr', '5-10yr', 'Above 10yr', 'Unknown'],
    'Service_year_of_vehicle': ['Below 1yr', '1-2yr', '2-5yrs', '5-10yrs', 'Above 10yr', 'Unknown'],
    'Accident_severity': ['Slight Injury', 'Serious Injury', 'Fatal injury'],
      'Cause_of_accident': ['No priority to vehicle', 'Overspeed', 'Overloading', 'Improper parking', 'Driving carelessly', 'Unknown']
}

# Replace unexpected values in ordinal columns with "Unknown" to ensure smooth label encoding
for column, order in ordinal_columns.items():
    # Modified this line to handle numeric and string values
    dataset[column] = dataset[column].apply(lambda x: x if str(x) in order else "Unknown")

# Apply label encoding for ordinal columns
for column, order in ordinal_columns.items():
    label_encoder = LabelEncoder()
 # Fit the label encoder on the unique values in the column, including 'Unknown' if present
    label_encoder.fit(dataset[column].unique())
    dataset[column] = label_encoder.transform(dataset[column])

# Apply one-hot encoding for the remaining categorical columns
nominal_columns = [col for col in categorical_columns if col not in ordinal_columns]
dataset_encoded = pd.get_dummies(dataset, columns=nominal_columns, drop_first=True)

# Confirm the transformation by displaying the first few rows
dataset_encoded.head(), dataset_encoded.info(), dataset_encoded.describe()

#encoding numerical variables
from sklearn.preprocessing import StandardScaler

# Selecting numerical columns for scaling
numerical_features = dataset_encoded.select_dtypes(include=['float64', 'int64']).columns

# Apply Standardization (Z-score scaling) to all numerical features
scaler = StandardScaler()
dataset_encoded[numerical_features] = scaler.fit_transform(dataset_encoded[numerical_features])

# Review the standardized numerical columns
dataset_encoded[numerical_features].describe()

#ACCIDENT SEVERITY ML models decions tree and logistic regression
!pip install scikit-learn matplotlib  # Install necessary libraries

from sklearn.model_selection import train_test_split
import pandas as pd
import time
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Assuming 'X' is your feature matrix and 'y' is the target
X = dataset_encoded.drop('Accident_severity', axis=1)
y = dataset['Accident_severity']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize models
decision_tree = DecisionTreeClassifier(random_state=42)
logistic_regression = LogisticRegression(random_state=42, max_iter=1000)

# Train and evaluate Decision Tree
start_time = time.time()
decision_tree.fit(X_train, y_train)
dt_time = time.time() - start_time

# Decision Tree predictions and evaluation
y_pred_dt = decision_tree.predict(X_test)
dt_metrics = {
    "Accuracy": accuracy_score(y_test, y_pred_dt),
    "Precision": precision_score(y_test, y_pred_dt, average='weighted'),
    "Recall": recall_score(y_test, y_pred_dt, average='weighted'),
    "F1 Score": f1_score(y_test, y_pred_dt, average='weighted'),
    "Time (s)": dt_time
}

# Train and evaluate Logistic Regression
start_time = time.time()
logistic_regression.fit(X_train, y_train)
lr_time = time.time() - start_time

# Logistic Regression predictions and evaluation
y_pred_lr = logistic_regression.predict(X_test)
lr_metrics = {
    "Accuracy": accuracy_score(y_test, y_pred_lr),
    "Precision": precision_score(y_test, y_pred_lr, average='weighted'),
    "Recall": recall_score(y_test, y_pred_lr, average='weighted'),
    "F1 Score": f1_score(y_test, y_pred_lr, average='weighted'),
    "Time (s)": lr_time
}

# Display model evaluation metrics
print("Decision Tree Metrics:", dt_metrics)
print("Logistic Regression Metrics:", lr_metrics)

# Visualization 1: Decision Tree Plot
plt.figure(figsize=(20, 10))

# Get unique class labels from the target variable 'y'
class_labels = y.unique()
# Sort them so the order remains consistent
class_labels.sort()
# Convert the class labels into a list and ensure they are strings
class_names = [str(label) for label in class_labels]

plot_tree(decision_tree, feature_names=X.columns, class_names=class_names, filled=True)  # Use updated class_names
plt.title("Decision Tree Structure")
plt.show()
# Visualization 2: Confusion Matrix for Decision Tree
ConfusionMatrixDisplay.from_estimator(decision_tree, X_test, y_test, display_labels=['Slight Injury', 'Serious Injury', 'Fatal injury'])
plt.title("Confusion Matrix - Decision Tree")
plt.show()

# Visualization 3: Confusion Matrix for Logistic Regression
ConfusionMatrixDisplay.from_estimator(logistic_regression, X_test, y_test, display_labels=['Slight Injury', 'Serious Injury', 'Fatal injury'])
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

# Import necessary libraries for LIME
!pip install lime  # Install the LIME package
import lime
from lime.lime_tabular import LimeTabularExplainer
import numpy as np

# Initialize the LIME explainer with training data
explainer = LimeTabularExplainer(
    training_data=np.array(X_train),
    feature_names=X.columns,
    class_names=['Slight Injury', 'Serious Injury', 'Fatal injury'],
    mode='classification'
)

# Select a sample from the test set to explain (you can select any sample)
sample_index = 0  # Example index; you may adjust this to explore different instances
sample = X_test.iloc[sample_index].values

# Explain the selected instance using LIME
exp = explainer.explain_instance(
    data_row=sample,
    predict_fn=logistic_regression.predict_proba
)

# Display the explanation in notebook format
exp.show_in_notebook(show_table=True)

# Import SHAP
import shap
import numpy as np

# Ensure no NaNs in the data
X_train = X_train.fillna(0)
X_test = X_test.fillna(0)

# Limit SHAP calculations to a subset of X_test for speed
X_test_subset = X_test.sample(50)  # Adjust the sample size based on desired accuracy/speed trade-off

# Initialize KernelExplainer for more robustness, using a subset of the training data as background
background = X_train.sample(100)  # Use a subset as background for KernelExplainer
shap_explainer = shap.KernelExplainer(logistic_regression.predict_proba, background)

# Compute SHAP values for the test subset
shap_values = shap_explainer.shap_values(X_test_subset)

# Summary Plot for Global Interpretability on the subset
shap.summary_plot(shap_values, X_test_subset, plot_type="bar", feature_names=X.columns)

# Force Plot for Local Interpretability of a Sample from the subset
sample_index = 0  # Use an index from the subset
# Select the SHAP values for a specific class (e.g., class 1)
class_index = 1  # Change this to the desired class index (0, 1, or 2)

# Corrected force_plot call
shap.force_plot(
    shap_explainer.expected_value[class_index],  # Expected value for the specific class
    shap_values[class_index][sample_index],       # SHAP values for the specific class and sample
    X_test_subset.iloc[sample_index],            # Features for the sample
    feature_names=X.columns                      # Provide feature names for better readability
)


# Alternative: Using LinearExplainer for Logistic Regression, if supported
shap_explainer = shap.LinearExplainer(logistic_regression, X_train)

# Compute SHAP values for the test subset
shap_values = shap_explainer.shap_values(X_test_subset)

# 1. Global Interpretability: SHAP Summary Plot for the subset
shap.summary_plot(shap_values, X_test_subset, plot_type="bar", feature_names=X.columns)

# 2. Local Interpretability: SHAP Force Plot for a Single Instance from the subset
sample_index = 0  # Choose an index from the subset to explore different samples
shap.force_plot(shap_explainer.expected_value, shap_values[sample_index], X_test_subset.iloc[sample_index])

print(X_train)
print(X_test)

from sklearn.inspection import PartialDependenceDisplay
import matplotlib.pyplot as plt

# Select a few key features based on prior analysis or feature importance
selected_features = [0, 1, 2]  # Replace with feature indices or names based on importance

# Get unique class labels from the target variable
classes = np.unique(y)

# 1. Partial Dependence Plots for Decision Tree, specifying the target class
fig, ax = plt.subplots(figsize=(15, 5))
display = PartialDependenceDisplay.from_estimator(
    decision_tree,
    X_test,
    features=selected_features,
    feature_names=X.columns,
    ax=ax,
    target=classes[0] # Specify the target class here (e.g., the first class)
)
plt.suptitle("Partial Dependence Plots - Decision Tree (Target Class: {})".format(classes[0]))
plt.show()

# 2. Partial Dependence Plots for Logistic Regression, specifying the target class
fig, ax = plt.subplots(figsize=(15, 5))
display = PartialDependenceDisplay.from_estimator(
    logistic_regression,
    X_test,
    features=selected_features,
    feature_names=X.columns,
    ax=ax,
    target=classes[0] # Specify the target class here (e.g., the first class)
)
plt.suptitle("Partial Dependence Plots - Logistic Regression (Target Class: {})".format(classes[0]))
plt.show()

#CAUSE OF ACCIDENT ML models decions tree and logistic regression
!pip install scikit-learn matplotlib  # Install necessary libraries

from sklearn.model_selection import train_test_split
import pandas as pd
import time
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Assuming 'X' is your feature matrix and 'y' is the target
X = dataset_encoded.drop('Cause_of_accident', axis=1)
y = dataset['Cause_of_accident']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize models
decision_tree = DecisionTreeClassifier(random_state=42)
logistic_regression = LogisticRegression(random_state=42, max_iter=1000)

# Train and evaluate Decision Tree
start_time = time.time()
decision_tree.fit(X_train, y_train)
dt_time = time.time() - start_time

# Decision Tree predictions and evaluation
y_pred_dt = decision_tree.predict(X_test)
dt_metrics = {
    "Accuracy": accuracy_score(y_test, y_pred_dt),
    "Precision": precision_score(y_test, y_pred_dt, average='weighted'),
    "Recall": recall_score(y_test, y_pred_dt, average='weighted'),
    "F1 Score": f1_score(y_test, y_pred_dt, average='weighted'),
    "Time (s)": dt_time
}

# Train and evaluate Logistic Regression
start_time = time.time()
logistic_regression.fit(X_train, y_train)
lr_time = time.time() - start_time

# Logistic Regression predictions and evaluation
y_pred_lr = logistic_regression.predict(X_test)
lr_metrics = {
    "Accuracy": accuracy_score(y_test, y_pred_lr),
    "Precision": precision_score(y_test, y_pred_lr, average='weighted'),
    "Recall": recall_score(y_test, y_pred_lr, average='weighted'),
    "F1 Score": f1_score(y_test, y_pred_lr, average='weighted'),
    "Time (s)": lr_time
}

# Display model evaluation metrics
print("Decision Tree Metrics:", dt_metrics)
print("Logistic Regression Metrics:", lr_metrics)

# Visualization 1: Decision Tree Plot
plt.figure(figsize=(20, 10))

# Get unique class labels from the target variable 'y'
class_labels = y.unique()
# Sort them so the order remains consistent
class_labels.sort()
# Convert the class labels into a list and ensure they are strings
class_names = [str(label) for label in class_labels]

plot_tree(decision_tree, feature_names=X.columns, class_names=class_names, filled=True)  # Use updated class_names
plt.title("Decision Tree Structure")
plt.show()
# Visualization 2: Confusion Matrix for Decision Tree
from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Create the confusion matrix display with smaller labels and adjusted rotation
disp = ConfusionMatrixDisplay.from_estimator(
    decision_tree, X_test, y_test,
    display_labels=['No priority to vehicle', 'Overspeed', 'Overloading', 'Improper parking', 'Driving carelessly', 'Unknown'],
    cmap='Blues'  # Optional: change color map for better clarity
)
plt.title("Confusion Matrix - Decision Tree")
plt.xticks(fontsize=8, rotation=45, ha='right')  # Smaller font size and angled labels for x-axis
plt.yticks(fontsize=8)  # Smaller font size for y-axis
plt.show()


# Visualization 3: Confusion Matrix for Logistic Regression
from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Create the confusion matrix display with smaller labels and adjusted rotation
disp = ConfusionMatrixDisplay.from_estimator(
    logistic_regression, X_test, y_test,
    display_labels=['No priority to vehicle', 'Overspeed', 'Overloading', 'Improper parking', 'Driving carelessly', 'Unknown'],
    cmap='Blues'  # Optional: change color map for better clarity
)
plt.title("Confusion Matrix - Logistic Regression")
plt.xticks(fontsize=8, rotation=45, ha='right')  # Smaller font size and angled labels for x-axis
plt.yticks(fontsize=8)  # Smaller font size for y-axis
plt.show()

# Import necessary libraries for LIME
!pip install lime  # Install the LIME package
import lime
from lime.lime_tabular import LimeTabularExplainer
import numpy as np

# Initialize the LIME explainer with training data
explainer = LimeTabularExplainer(
    training_data=np.array(X_train),
    feature_names=X.columns,
    class_names=['No priority to vehicle', 'Overspeed', 'Overloading', 'Improper parking', 'Driving carelessly', 'Unknown'],
    mode='classification'
)

# Select a sample from the test set to explain (you can select any sample)
sample_index = 0  # Example index; you may adjust this to explore different instances
sample = X_test.iloc[sample_index].values

# Explain the selected instance using LIME
exp = explainer.explain_instance(
    data_row=sample,
    predict_fn=logistic_regression.predict_proba
)

# Display the explanation in notebook format
exp.show_in_notebook(show_table=True)

# Import SHAP
import shap
import numpy as np

# Ensure no NaNs in the data
X_train = X_train.fillna(0)
X_test = X_test.fillna(0)

# Limit SHAP calculations to a subset of X_test for speed
X_test_subset = X_test.sample(50)  # Adjust the sample size based on desired accuracy/speed trade-off

# Initialize KernelExplainer for more robustness, using a subset of the training data as background
background = X_train.sample(100)  # Use a subset as background for KernelExplainer
shap_explainer = shap.KernelExplainer(logistic_regression.predict_proba, background)

# Compute SHAP values for the test subset
shap_values = shap_explainer.shap_values(X_test_subset)

# Summary Plot for Global Interpretability on the subset
shap.summary_plot(shap_values, X_test_subset, plot_type="bar", feature_names=X.columns)

# Force Plot for Local Interpretability of a Sample from the subset
sample_index = 0  # Use an index from the subset
# Select the SHAP values for a specific class (e.g., class 1)
class_index = 1  # Change this to the desired class index (0, 1, or 2)

# Corrected force_plot call
shap.force_plot(
    shap_explainer.expected_value[class_index],  # Expected value for the specific class
    shap_values[class_index][sample_index],       # SHAP values for the specific class and sample
    X_test_subset.iloc[sample_index],            # Features for the sample
    feature_names=X.columns                      # Provide feature names for better readability
)
# Alternative: Using LinearExplainer for Logistic Regression, if supported
shap_explainer = shap.LinearExplainer(logistic_regression, X_train)

# Compute SHAP values for the test subset
shap_values = shap_explainer.shap_values(X_test_subset)

# 1. Global Interpretability: SHAP Summary Plot for the subset
shap.summary_plot(shap_values, X_test_subset, plot_type="bar", feature_names=X.columns)

# 2. Local Interpretability: SHAP Force Plot for a Single Instance from the subset
sample_index = 0  # Choose an index from the subset to explore different samples
shap.force_plot(shap_explainer.expected_value, shap_values[sample_index], X_test_subset.iloc[sample_index])

from sklearn.inspection import PartialDependenceDisplay
import matplotlib.pyplot as plt

# Select a few key features based on prior analysis or feature importance
selected_features = [0, 1, 2]  # Replace with feature indices or names based on importance

# Get unique class labels from the target variable
classes = np.unique(y)

# 1. Partial Dependence Plots for Decision Tree, specifying the target class
fig, ax = plt.subplots(figsize=(15, 5))
display = PartialDependenceDisplay.from_estimator(
    decision_tree,
    X_test,
    features=selected_features,
    feature_names=X.columns,
    ax=ax,
    target=classes[0] # Specify the target class here (e.g., the first class)
)
plt.suptitle("Partial Dependence Plots - Decision Tree (Target Class: {})".format(classes[0]))
plt.show()

# 2. Partial Dependence Plots for Logistic Regression, specifying the target class
fig, ax = plt.subplots(figsize=(15, 5))
display = PartialDependenceDisplay.from_estimator(
    logistic_regression,
    X_test,
    features=selected_features,
    feature_names=X.columns,
    ax=ax,
    target=classes[0] # Specify the target class here (e.g., the first class)
)
plt.suptitle("Partial Dependence Plots - Logistic Regression (Target Class: {})".format(classes[0]))
plt.show()

